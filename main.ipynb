{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26002,
     "status": "ok",
     "timestamp": 1701346167977,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "l3gyPdY9C9d1",
    "outputId": "26793081-7834-4b49-8248-606f62b8ea4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-01 19:26:21--  http://www.manythings.org/anki/pes-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 150371 (147K) [application/zip]\n",
      "Saving to: ‘pes-eng.zip.3’\n",
      "\n",
      "pes-eng.zip.3       100%[===================>] 146.85K  44.2KB/s    in 3.3s    \n",
      "\n",
      "2023-12-01 19:26:25 (44.2 KB/s) - ‘pes-eng.zip.3’ saved [150371/150371]\n",
      "\n",
      "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/pes-eng.zip\n",
    "!unzip -q pes-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1701352211511,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "LKJp6iHtDXsa"
   },
   "outputs": [],
   "source": [
    "text_file=\"pes.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines=f.read().split(\"\\n\")[:-1]\n",
    "text_pairs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701352212029,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "rKCCENaoDj4E"
   },
   "outputs": [],
   "source": [
    "for line in lines :\n",
    "    english, persian ,null = line.split(\"\\t\")\n",
    "    persian = \"[start] \" + persian + \" [end]\"\n",
    "    text_pairs.append((english,persian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701352212030,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "Uw0aOQm4Dk0z",
    "outputId": "b4874007-b694-44b6-b42e-902399856cd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Marriage is the main cause of all divorces.', '[start] ازدواج علت اصلی همهٔ طلاقهاست. [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701352212030,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "0MuQwIc9Dl1Y"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1701352212549,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "i9KN547_Dm95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 19:27:37.748803: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 19:27:38.643723: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "vocab_size = 2500\n",
    "sequence_length = 15\n",
    "\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_persian_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_persian_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701352212549,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "2BUav9-ZD1PS"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, pes):\n",
    "    eng = source_vectorization(eng)\n",
    "    pes = target_vectorization(pes)\n",
    "    return ({\n",
    "        \"english\": eng,\n",
    "        \"persian\": pes[:, :-1],\n",
    "    }, pes[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, pes_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    pes_texts = list(pes_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, pes_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1701352213152,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "AiHvewa9EYdN",
    "outputId": "a6a241b7-128c-4457-bdac-dfa9edb5795b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['english'].shape: (64, 15)\n",
      "inputs['persian'].shape: (64, 15)\n",
      "targets.shape: (64, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 19:27:38.936462: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype resource\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2023-12-01 19:27:38.936725: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_12' with dtype string\n",
      "\t [[{{node Placeholder/_12}}]]\n",
      "2023-12-01 19:27:38.966442: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['persian'].shape: {inputs['persian'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701352213152,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "Xc23_zyfEdhX"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        else:\n",
    "            padding_mask = mask\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "Positional embeddings (تعبیه‌های موقعیتی) یکی از عناصر کلیدی در مدل‌های پردازش زبان طبیعی (NLP) مبتنی بر ترتیب مانند Transformer است. این تعبیه‌ها برای افزودن اطلاعات مرتبط با موقعیت (ترتیب) کلمات در جمله به بردارهای ویژگی هر کلمه استفاده می‌شوند.\n",
    "\n",
    "در معماری Transformer، که به طور خاص برای پردازش دنباله‌های طولانی مانند جملات زبان طبیعی ایجاد شده است، از self-attention mechanism استفاده می‌شود. این مکانیزم به شبکه این امکان را می‌دهد تا به ویژگی‌های هر کلمه با توجه به تمام کلمات دنباله وزن دهد. با این حال، اطلاعات مربوط به ترتیب کلمات در جمله از دست می‌روند چرا که مدل به تنهایی اطلاعات ترتیبی را نمی‌فهمد.\n",
    "\n",
    "برای حل این مشکل، تعبیه‌های موقعیتی اضافه می‌شوند. این تعبیه‌ها به هر کلمه یا موقعیت در جمله یک بردار مخصوص اختصاص می‌دهند. این بردارها به عنوان ورودی به لایه‌های Transformer اضافه می‌شوند و با ویژگی‌های متناظر هر کلمه جمع می‌شوند. به این ترتیب، مدل قادر به درک بهتر ترتیب موقعیتی کلمات می‌شود.\n",
    "\n",
    "تعبیه‌های موقعیتی معمولاً با استفاده از توابع ریاضی یا جدول‌های ثابت ایجاد می‌شوند و در مرحله اولیه آموزش مدل به آنها یادگیری نمی‌شود. این اطلاعات موقعیتی بهترین شکل را برای ورودی به شبکه فراهم می‌کنند و به مدل کمک می‌کنند که وابستگی‌های زمانی را در داده‌های ورودی بشناسد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701352213152,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "dTb7iW_lEfSe"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701352213152,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "WMpBW9rZEiXD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LayerNormalization, Layer, Dense, ReLU, Dropout\n",
    "\n",
    "# Implementing the Add & Norm Layer\n",
    "class AddNormalization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AddNormalization, self).__init__(**kwargs)\n",
    "        self.layer_norm = LayerNormalization()  # Layer normalization layer\n",
    "\n",
    "    def call(self, x, sublayer_x):\n",
    "        # The sublayer input and output need to be of the same shape to be summed\n",
    "        add = x + sublayer_x\n",
    "\n",
    "        # Apply layer normalization to the sum\n",
    "        return self.layer_norm(add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701352213153,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "FwNzU1p7J--y"
   },
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "تفاوت attention و self attention\n",
    "\n",
    "Attention و self-attention (یا به نام دیگر scaled dot-product attention) دو ویژگی مرتبط با مدل‌های Transformer هستند، اما مفاهیم متفاوتی دارند.\n",
    "\n",
    "1. **Attention:**\n",
    "   در Attention، ورودی شبکه به تعداد سرهایی (heads) تقسیم می‌شود و سپس هر سر به صورت جداگانه با ویژگی‌های ورودی ترکیب می‌شود. به عبارت دیگر، هر سر به دنبال توجه به نقاط مختلف دنباله است و در نهایت خروجی‌های این سرها با یکدیگر ترکیب می‌شوند.\n",
    "\n",
    "2. **Self-Attention (Scaled Dot-Product Attention):**\n",
    "   در self-attention، توجه به خود (self) انجام می‌شود، به این معنی که هر عنصر از دنباله به سایر عناصر توجه می‌کند. برای هر ورودی، توجه به تمام ورودی‌های دیگر با استفاده از محاسبه dot-product انجام می‌شود. این نوع توجه به شبکه این امکان را می‌دهد که اطلاعات متقابل بین همه عناصر دنباله را دریافت کند.\n",
    "\n",
    "   در self-attention، برای کنترل مقیاس و تعادل، dot-product نرمال شده می‌شود و سپس به عنوان وزن‌های توجه برای ترکیب خطی ویژگی‌ها استفاده می‌شود.\n",
    "\n",
    "در واقع، self-attention یک نوع از attention است که در آن توجه به خود (self) و همچنین توجه به نقاط مختلف دنباله انجام می‌شود. این امکان باعث می‌شود که شبکه قادر به درک تعاملات داخلی در دنباله باشد و ارتباطات موقعیتی و ترتیبی بین عناصر را در نظر گیرد.\n",
    "\n",
    "در پایین ما از دو مدل برای مقایسه هر دو روش با استفاده از ۸ سر استفاده میکنیم .\n",
    "\n",
    "برای توضیح دقیق تر یک ویس در تلگرام ارسال خواهد شد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701352213153,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "MHsvwblYKxwS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "در این بخش با استفاده از توضیحات بالا ما از ۸ سر برای attention استفاده میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1701352213936,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "fX0dqdQTHby-"
   },
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"persian\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1164295,
     "status": "ok",
     "timestamp": 1701353378229,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "TV7Eoit8IqIR",
    "outputId": "f53f83b3-b9ca-4db7-b121-af4471c80a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 19:27:39.349049: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype int64\n",
      "\t [[{{node Placeholder/_13}}]]\n",
      "2023-12-01 19:27:39.349299: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype int64\n",
      "\t [[{{node Placeholder/_13}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 5.3251 - accuracy: 0.2526"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 19:27:47.325630: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype resource\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "2023-12-01 19:27:47.331524: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_12' with dtype string\n",
      "\t [[{{node Placeholder/_12}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 9s 212ms/step - loss: 5.3251 - accuracy: 0.2526 - val_loss: 4.1337 - val_accuracy: 0.3600\n",
      "Epoch 2/30\n",
      "35/35 [==============================] - 6s 173ms/step - loss: 4.5914 - accuracy: 0.3146 - val_loss: 3.8885 - val_accuracy: 0.3987\n",
      "Epoch 3/30\n",
      "35/35 [==============================] - 6s 178ms/step - loss: 4.1891 - accuracy: 0.3533 - val_loss: 3.7678 - val_accuracy: 0.3878\n",
      "Epoch 4/30\n",
      "35/35 [==============================] - 7s 186ms/step - loss: 3.8868 - accuracy: 0.3841 - val_loss: 3.7344 - val_accuracy: 0.3769\n",
      "Epoch 5/30\n",
      "35/35 [==============================] - 6s 180ms/step - loss: 3.5503 - accuracy: 0.4213 - val_loss: 3.5739 - val_accuracy: 0.4026\n",
      "Epoch 6/30\n",
      "35/35 [==============================] - 6s 176ms/step - loss: 3.2690 - accuracy: 0.4556 - val_loss: 3.5283 - val_accuracy: 0.4212\n",
      "Epoch 7/30\n",
      "35/35 [==============================] - 6s 179ms/step - loss: 3.0145 - accuracy: 0.4869 - val_loss: 3.7216 - val_accuracy: 0.4066\n",
      "Epoch 8/30\n",
      "35/35 [==============================] - 6s 181ms/step - loss: 2.7697 - accuracy: 0.5130 - val_loss: 3.5591 - val_accuracy: 0.4024\n",
      "Epoch 9/30\n",
      "35/35 [==============================] - 6s 169ms/step - loss: 2.5164 - accuracy: 0.5542 - val_loss: 3.4380 - val_accuracy: 0.4306\n",
      "Epoch 10/30\n",
      "35/35 [==============================] - 6s 181ms/step - loss: 2.3368 - accuracy: 0.5810 - val_loss: 3.6334 - val_accuracy: 0.4029\n",
      "Epoch 11/30\n",
      "35/35 [==============================] - 6s 181ms/step - loss: 2.0789 - accuracy: 0.6188 - val_loss: 3.5298 - val_accuracy: 0.4321\n",
      "Epoch 12/30\n",
      "35/35 [==============================] - 6s 178ms/step - loss: 1.8957 - accuracy: 0.6469 - val_loss: 3.7348 - val_accuracy: 0.4101\n",
      "Epoch 13/30\n",
      "35/35 [==============================] - 6s 181ms/step - loss: 1.7376 - accuracy: 0.6748 - val_loss: 3.9129 - val_accuracy: 0.4016\n",
      "Epoch 14/30\n",
      "35/35 [==============================] - 6s 180ms/step - loss: 1.5435 - accuracy: 0.7061 - val_loss: 3.7719 - val_accuracy: 0.4190\n",
      "Epoch 15/30\n",
      "35/35 [==============================] - 6s 163ms/step - loss: 1.3893 - accuracy: 0.7347 - val_loss: 4.0817 - val_accuracy: 0.4004\n",
      "Epoch 16/30\n",
      "35/35 [==============================] - 6s 178ms/step - loss: 1.2359 - accuracy: 0.7650 - val_loss: 3.7404 - val_accuracy: 0.4254\n",
      "Epoch 17/30\n",
      "35/35 [==============================] - 6s 174ms/step - loss: 1.1110 - accuracy: 0.7893 - val_loss: 3.9081 - val_accuracy: 0.4148\n",
      "Epoch 18/30\n",
      "35/35 [==============================] - 6s 162ms/step - loss: 0.9600 - accuracy: 0.8219 - val_loss: 3.9256 - val_accuracy: 0.4172\n",
      "Epoch 19/30\n",
      "35/35 [==============================] - 7s 188ms/step - loss: 0.8307 - accuracy: 0.8476 - val_loss: 3.8838 - val_accuracy: 0.4210\n",
      "Epoch 20/30\n",
      "35/35 [==============================] - 6s 177ms/step - loss: 0.7574 - accuracy: 0.8621 - val_loss: 4.2631 - val_accuracy: 0.3984\n",
      "Epoch 21/30\n",
      "35/35 [==============================] - 6s 181ms/step - loss: 0.6639 - accuracy: 0.8763 - val_loss: 4.0399 - val_accuracy: 0.4212\n",
      "Epoch 22/30\n",
      "35/35 [==============================] - 6s 186ms/step - loss: 0.5702 - accuracy: 0.8945 - val_loss: 4.3894 - val_accuracy: 0.4011\n",
      "Epoch 23/30\n",
      "35/35 [==============================] - 6s 165ms/step - loss: 0.4953 - accuracy: 0.9140 - val_loss: 4.2830 - val_accuracy: 0.4145\n",
      "Epoch 24/30\n",
      "35/35 [==============================] - 6s 185ms/step - loss: 0.4399 - accuracy: 0.9198 - val_loss: 4.5100 - val_accuracy: 0.4066\n",
      "Epoch 25/30\n",
      "35/35 [==============================] - 6s 173ms/step - loss: 0.3850 - accuracy: 0.9303 - val_loss: 4.5414 - val_accuracy: 0.4039\n",
      "Epoch 26/30\n",
      "35/35 [==============================] - 6s 183ms/step - loss: 0.4625 - accuracy: 0.9137 - val_loss: 4.4698 - val_accuracy: 0.4115\n",
      "Epoch 27/30\n",
      "35/35 [==============================] - 6s 179ms/step - loss: 0.2823 - accuracy: 0.9480 - val_loss: 4.6262 - val_accuracy: 0.4066\n",
      "Epoch 28/30\n",
      "35/35 [==============================] - 7s 191ms/step - loss: 0.2673 - accuracy: 0.9510 - val_loss: 4.5575 - val_accuracy: 0.4083\n",
      "Epoch 29/30\n",
      "35/35 [==============================] - 6s 182ms/step - loss: 0.2487 - accuracy: 0.9509 - val_loss: 4.6524 - val_accuracy: 0.4118\n",
      "Epoch 30/30\n",
      "35/35 [==============================] - 6s 179ms/step - loss: 0.2298 - accuracy: 0.9535 - val_loss: 4.8042 - val_accuracy: 0.4058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f52f42e2dd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "در یادگیری بالا ما به دقت 40 درصد رسیدیم،از آنجایی که تعداد جملات ما بسیار کم بود این دقت تا حد زیادی قابل قبول از و اور فیت در آن دیده نمیشود."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1701353504191,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "uxnCRO1ukJYd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pes_vocab = target_vectorization.get_vocabulary()\n",
    "pes_index_lookup = dict(zip(range(len(pes_vocab)), pes_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = pes_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1701353591919,
     "user": {
      "displayName": "Mohammad Abbasi",
      "userId": "03715019020550270340"
     },
     "user_tz": -210
    },
    "id": "LNz090k1klHu",
    "outputId": "04d9a8e9-b86c-4e62-a4a5-78690a0d918b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] ما چه می روی؟ [end]\n"
     ]
    }
   ],
   "source": [
    "    print(decode_sequence(\"we are going out\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzStKQJ2lHG0YyMKUsjUMY",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
